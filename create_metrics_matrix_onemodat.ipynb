{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23fd47e4-5596-4abb-8553-071dfb7ffeba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-ESM1-5 getting grid info\n",
      "CESM2 getting grid info\n",
      "GFDL-ESM4 getting grid info\n",
      "GISS_E2.1 getting grid info\n",
      "NorESM2-LM getting grid info\n",
      "MPI-ESM1-2-LR getting grid info\n",
      "CNRM-ESM2-1 getting grid info\n",
      "HadCM3LC-Bris getting grid info\n",
      "UKESM1.2 getting grid info\n",
      "processing model: HadCM3LC-Bris\n",
      "processing run: flat10\n",
      "processing variable: cLitter\n",
      "loading variable: cLitter\n",
      "no data for cLitter\n",
      "processing run: flat10_zec\n",
      "processing variable: cLitter\n",
      "loading variable: cLitter\n",
      "no data for cLitter\n",
      "processing run: flat10_cdr\n",
      "processing variable: cLitter\n",
      "loading variable: cLitter\n",
      "no data for cLitter\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# ## Create a netcdf file with a matrix of processed time series\n",
    "# this works with environment npl2025b\n",
    "# to run on the command line:\n",
    "#\n",
    "# module load conda\n",
    "# conda activate npl-2025b\n",
    "# python create_metrics_matrix.py\n",
    "\n",
    "\n",
    "# This is a script version of a python notebook\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import numpy.ma as ma\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "import time\n",
    "import cftime\n",
    "import netCDF4 as nc\n",
    "from datetime import timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "\n",
    "\n",
    "import nc_time_axis\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# --- custom files\n",
    "# load custom functions for analyzing flat10\n",
    "\n",
    "from loading_function_flat10 import load_flat10, load_one_model, load_one_model_onevar, load_grid, select_time_slice, weighted_temporal_mean \n",
    "\n",
    "\n",
    "# ###-------------####\n",
    "# define which runs and models\n",
    "\n",
    "outputdir= '/glade/campaign/cgd/tss/people/aswann/flat10/'\n",
    "\n",
    "modellist_orig= ['ACCESS-ESM1-5',  \n",
    "            'CESM2',    \n",
    "            'GFDL-ESM4',  \n",
    "            'GISS_E2.1',  \n",
    "            'NorESM2-LM',\n",
    "            'MPI-ESM1-2-LR',\n",
    "            'CNRM-ESM2-1',\n",
    "            'HadCM3LC-Bris',\n",
    "            'UKESM1.2']\n",
    "modellist=modellist_orig\n",
    "\n",
    "runlist = ['flat10','flat10_zec','flat10_cdr']\n",
    "# use a wildcard to capture different ways the folders and runs are named across models\n",
    "runlist_wc = ['*lat10','*zec','*cdr']\n",
    "\n",
    "varlist_load=['cVeg','cSoil','cLitter','nbp','gpp','rh','tas','pr'] #, 'gpp','fgco2', 'ra', 'rh']#, 'npp'] # not working beyond nbp for norESM\n",
    "varlist_analyze=['cVeg','cSoil','cTot','cLitter','nbp','gpp','rh','tas','pr']\n",
    "varlist=varlist_load\n",
    "unitslist=['kgC m-2','kgC m-2','kgC m-2','kgC m-2 s-1','kgC m-2 s-1','kgC m-2 s-1','K','kg m-2 s-1']\n",
    "\n",
    "\n",
    "# global and three latitude bands: trop, mid, high\n",
    "latlist=['global','highlat','troplat','midlat']\n",
    "troplat=30\n",
    "highlat=60\n",
    "\n",
    "## unit conversions\n",
    "#unitconversions\n",
    "sperday=60*60*24\n",
    "speryr=60*60*24*365\n",
    "\n",
    "PgperKg = 1e-12\n",
    "# to convert kg m-2 s-1 to kg/m2/yr multiply by speryr\n",
    "\n",
    "# initialize a dictionary to hold all of the data\n",
    "data_dict={}\n",
    "\n",
    "\n",
    "# ###---------------####\n",
    "\n",
    "#-- load grid info\n",
    "data_dict = load_grid(data_dict,modellist)\n",
    "\n",
    "\n",
    "#-- load data\n",
    "#data_dict=load_flat10(data_dict, modellist, runlist, runlist_wc, varlist)\n",
    "\n",
    "#-- toggle to analysis lists\n",
    "modellist=modellist_orig\n",
    "varlist=['cLitter']\n",
    "modellist=['HadCM3LC-Bris']\n",
    "\n",
    "# ###---------------####\n",
    "# create matrix of zonal mean time series for \n",
    "\n",
    "#- initialize\n",
    "C_global_mat= np.full([350,len(modellist),len(runlist),len(varlist)],np.nan)\n",
    "C_highlat_mat= np.full([350,len(modellist),len(runlist),len(varlist)],np.nan)\n",
    "C_troplat_mat= np.full([350,len(modellist),len(runlist),len(varlist)],np.nan)\n",
    "C_midlat_mat= np.full([350,len(modellist),len(runlist),len(varlist)],np.nan)\n",
    "\n",
    "# create a time series of years for the first dimension\n",
    "ts= np.arange(350)\n",
    "\n",
    "for m in range(len(modellist)):\n",
    "#for m in range(len(['GFDL-ESM4',  'GISS_E2.1',  'NorESM2-LM','MPI-ESM1-2-LR'])):\n",
    "    model=modellist[m]\n",
    "    print('processing model: ' +model)\n",
    "\n",
    "    # get area and landfrac from the dictionary where they have been pre-loaded\n",
    "    ds_area = data_dict[modellist[m] +'_' +'areacella']\n",
    "    ds_landfrac = data_dict[modellist[m] +'_' +'landfrac']\n",
    "    \n",
    "    #----loop over experiments----# \n",
    "    for e in range(len(runlist)):\n",
    "        run = runlist[e]\n",
    "        print('processing run: ' +run)\n",
    "\n",
    "        #ds=load_one_model(model,runlist_wc[e],varlist)\n",
    "        #ds=data_dict[modellist[m] +'_' +runlist[e]]\n",
    "\n",
    "\n",
    "        #----loop over variables----#\n",
    "        for v in range(len(varlist)):\n",
    "            var=varlist[v]\n",
    "            print('processing variable: ' +var)\n",
    "\n",
    "            ds=None\n",
    "            ds=load_one_model_onevar(model,runlist_wc[e],var)\n",
    "            \n",
    "            if ds is not None: # catch the case when the variable doesn't exist\n",
    "                    \n",
    "    \n",
    "                if model=='CESM2':\n",
    "                    area = ds_area['areacella'].squeeze().reindex_like(ds, method='nearest',tolerance=0.05)\n",
    "                else:\n",
    "                    area = ds_area['areacella'].reindex_like(ds, method='nearest',tolerance=0.05)\n",
    "                \n",
    "                landfrac=ds_landfrac['sftlf'].reindex_like(ds, method='nearest',tolerance=0.05)\n",
    "                \n",
    "                if landfrac.max(dim=['lat','lon'])>1: #test if landfrac is on a 0-100 or 0-1 scale\n",
    "                    landfrac=landfrac/100\n",
    "                    \n",
    "                landarea=area*landfrac\n",
    "                 \n",
    "    \n",
    "                # NorESM has drift that needs to be corrected\n",
    "                # load the drift correction matrix and remove the drift\n",
    "                if model=='NorESM2-LM':\n",
    "                    if var=='cVeg':\n",
    "                        field = pickle.load(open('/glade/campaign/cgd/tss/people/aswann/flat10/NorESM2-LM/NorESM2-LM_2D_TOTVEGC_ann_drift.pkl','rb'))\n",
    "                        adj_matrix = xr.DataArray(np.squeeze(field), dims=['lat','lon'], coords={'latitude': ds.lat, 'longitude':ds.lon})##,unit={'g C m-2 yr-1'})\n",
    "                        ty=ds['time'].dt.year\n",
    "                        tyindx=ty-ty[0]+1\n",
    "                        adjustment = adj_matrix* tyindx*(1/1000) #this is the drift for each time point and each gridcell in kg C m-2 yr-1\n",
    "    \n",
    "                        ds[var]=ds[var]+adjustment # remove the drift from the variable\n",
    "                        \n",
    "                    elif var=='cSoil':\n",
    "                        field = pickle.load(open('/glade/campaign/cgd/tss/people/aswann/flat10/NorESM2-LM/NorESM2-LM_2D_TOTSOMC_ann_drift.pkl','rb'))\n",
    "                        adj_matrix = xr.DataArray(np.squeeze(field), dims=['lat','lon'], coords={'latitude': ds.lat, 'longitude':ds.lon})##,unit={'g C m-2 yr-1'})\n",
    "                        ty=ds['time'].dt.year\n",
    "                        tyindx=ty-ty[0]+1\n",
    "                        adjustment = adj_matrix* tyindx*(1/1000) #this is the drift for each time point and each gridcell in kg C m-2 yr-1\n",
    "    \n",
    "                        ds[var]=ds[var]+adjustment # remove the drift from the variable\n",
    "                        \n",
    "                    elif var=='cLitter':\n",
    "                        field = pickle.load(open('/glade/campaign/cgd/tss/people/aswann/flat10/NorESM2-LM/NorESM2-LM_2D_TOTLITC_ann_drift.pkl','rb'))\n",
    "                        adj_matrix = xr.DataArray(np.squeeze(field), dims=['lat','lon'], coords={'latitude': ds.lat, 'longitude':ds.lon})##,unit={'g C m-2 yr-1'})\n",
    "                        ty=ds['time'].dt.year\n",
    "                        tyindx=ty-ty[0]+1\n",
    "                        adjustment = adj_matrix* tyindx*(1/1000) #this is the drift for each time point and each gridcell in kg C m-2 yr-1\n",
    "    \n",
    "                        ds[var]=ds[var]+adjustment # remove the drift from the variable\n",
    "    \n",
    "                data_var= weighted_temporal_mean(ds, var)\n",
    "    \n",
    "                # mask for nans \n",
    "                # Mask landarea where it's zero or NaN to avoid invalid values\n",
    "                valid_mask = (landarea > 0) & landarea.notnull()\n",
    "                masked_landarea = landarea.where(valid_mask)\n",
    "                masked_data = data_var.where(valid_mask)\n",
    "    \n",
    "                landarea_global = masked_landarea.sum(dim=['lat','lon'])\n",
    "                landarea_highlat = ((masked_landarea.where(ds.lat>=highlat)).sum(dim=['lat','lon']))\n",
    "                landarea_troplat = ((masked_landarea.where((ds.lat>=-troplat) & (ds.lat<=troplat))).sum(dim=['lat','lon']))\n",
    "                landarea_midlat = ((masked_landarea.where((ds.lat>=troplat) & (ds.lat<=highlat))).sum(dim=['lat','lon']))\n",
    "    \n",
    "                if var=='tas' or var=='pr': \n",
    "                    C_global =(((masked_data*masked_landarea)).sum(dim=['lat','lon']))/landarea_global\n",
    "                    C_highlat=(((masked_data*masked_landarea).where(ds.lat>=highlat)).sum(dim=['lat','lon']))/landarea_highlat\n",
    "                    C_troplat=(((masked_data*masked_landarea).where((ds.lat>=-troplat) & (ds.lat<=troplat))).sum(dim=['lat','lon']))/landarea_troplat\n",
    "                    C_midlat=(((masked_data*masked_landarea).where((ds.lat>=troplat) & (ds.lat<=highlat))).sum(dim=['lat','lon']))/landarea_midlat\n",
    "        \n",
    "                    #put into matrix \n",
    "                    C_global_mat[0:len(C_global),m,e,v]= C_global\n",
    "                    C_highlat_mat[0:len(C_global),m,e,v]= C_highlat\n",
    "                    C_troplat_mat[0:len(C_global),m,e,v]= C_troplat\n",
    "                    C_midlat_mat[0:len(C_global),m,e,v]= C_midlat\n",
    "                \n",
    "                else: # it is a carbon variable and we want to make a sum\n",
    "                    # total carbon on land. Becuase it is in units of carbon/area (kgC/m2), multiply by area\n",
    "                    # our area variable is in m2\n",
    "                    C_global =(((masked_data*masked_landarea)).sum(dim=['lat','lon']))\n",
    "                    C_highlat=((masked_data*masked_landarea).where(ds.lat>=highlat)).sum(dim=['lat','lon'])\n",
    "                    C_troplat=((masked_data*masked_landarea).where((ds.lat>=-troplat) & (ds.lat<=troplat))).sum(dim=['lat','lon'])\n",
    "                    C_midlat=((masked_data*masked_landarea).where((ds.lat>=troplat) & (ds.lat<=highlat))).sum(dim=['lat','lon'])\n",
    "        \n",
    "                    #put into matrix and convert to PgC (kgC => PgC, divide by 10^12)\n",
    "                    C_global_mat[0:len(C_global),m,e,v]= C_global*PgperKg\n",
    "                    C_highlat_mat[0:len(C_global),m,e,v]= C_highlat*PgperKg\n",
    "                    C_troplat_mat[0:len(C_global),m,e,v]= C_troplat*PgperKg\n",
    "                    C_midlat_mat[0:len(C_global),m,e,v]= C_midlat*PgperKg\n",
    "    \n",
    "                # reset values after the end of the time series to nan\n",
    "                C_global_mat[(len(C_global)):,m,e,v]=np.nan\n",
    "                C_highlat_mat[(len(C_highlat)):,m,e,v]=np.nan\n",
    "                C_troplat_mat[(len(C_troplat)):,m,e,v]=np.nan\n",
    "                C_midlat_mat[(len(C_midlat)):,m,e,v]=np.nan\n",
    "\n",
    "                del ds # remove the dataset from memory\n",
    "                del data_var # remove from memory\n",
    "                del masked_data\n",
    "\n",
    "# ###----------------####\n",
    "\n",
    "# put the matrix into an xarray dataset\n",
    "data_array_combined = np.full((len(ts), len(modellist), len(runlist), len(varlist), len(latlist)),np.nan)\n",
    "\n",
    "data_array_combined[:,:,:,:,0]=C_global_mat\n",
    "data_array_combined[:,:,:,:,1]=C_highlat_mat\n",
    "data_array_combined[:,:,:,:,2]=C_troplat_mat\n",
    "data_array_combined[:,:,:,:,3]=C_midlat_mat\n",
    "\n",
    "\n",
    "# ###----------------####\n",
    "# put into an xarray dataset\n",
    "\n",
    "ds_C_global= xr.Dataset(\n",
    "    {\n",
    "        \"data\": ([\"time\", \"model\", \"run\", \"var\",\"latrange\"], data_array_combined)\n",
    "    },\n",
    "    coords={\n",
    "        \"time\": ts,\n",
    "        \"model\": modellist,\n",
    "        \"run\": runlist,\n",
    "        \"var\": varlist,\n",
    "        \"latrange\": latlist\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# ###----------------####\n",
    "\n",
    "# - save the matrix to a netcdf file\n",
    "#ds_C_global.to_netcdf(\"C_metrics_matrix.nc\")\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b0e5a23-f93f-4bb8-8e9e-aeb1d98b906d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[nan],\n",
       "         [nan],\n",
       "         [nan]]],\n",
       "\n",
       "\n",
       "       [[[nan],\n",
       "         [nan],\n",
       "         [nan]]],\n",
       "\n",
       "\n",
       "       [[[nan],\n",
       "         [nan],\n",
       "         [nan]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[nan],\n",
       "         [nan],\n",
       "         [nan]]],\n",
       "\n",
       "\n",
       "       [[[nan],\n",
       "         [nan],\n",
       "         [nan]]],\n",
       "\n",
       "\n",
       "       [[[nan],\n",
       "         [nan],\n",
       "         [nan]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_midlat_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf55d398-6034-4269-9967-e13d14da1f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 1, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1466fbd8df70>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.shape(C_midlat_mat))\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "plt.plot(C_midlat_mat[:,:,1,0])\n",
    "\n",
    "\n",
    "#plt.plot(C_midlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea019e0-c0bd-48ce-9fc2-972622f667a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90851e-2058-4ea0-a5b0-2b5dad578a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10bf26c3-4d8d-473c-bc9b-d15850144604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-ESM1-5 getting grid info\n",
      "CESM2 getting grid info\n",
      "GFDL-ESM4 getting grid info\n",
      "GISS_E2.1 getting grid info\n",
      "NorESM2-LM getting grid info\n",
      "MPI-ESM1-2-LR getting grid info\n",
      "CNRM-ESM2-1 getting grid info\n",
      "HadCM3LC-Bris getting grid info\n",
      "UKESM1.2 getting grid info\n",
      "processing model: ACCESS-ESM1-5\n",
      "processing run: flat10\n",
      "processing variable: cVeg\n",
      "loading variable: cVeg\n",
      "finished loading ACCESS-ESM1-5 *lat10 cVeg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 219\u001b[39m\n\u001b[32m    216\u001b[39m C_midlat=((masked_data*masked_landarea).where((ds.lat>=troplat) & (ds.lat<=highlat))).sum(dim=[\u001b[33m'\u001b[39m\u001b[33mlat\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mlon\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    218\u001b[39m \u001b[38;5;66;03m#put into matrix and convert to PgC (kgC => PgC, divide by 10^12)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m \u001b[43mC_global_mat\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mC_global\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m= C_global*PgperKg\n\u001b[32m    220\u001b[39m C_highlat_mat[\u001b[32m0\u001b[39m:\u001b[38;5;28mlen\u001b[39m(C_global),m,e,v]= C_highlat*PgperKg\n\u001b[32m    221\u001b[39m C_troplat_mat[\u001b[32m0\u001b[39m:\u001b[38;5;28mlen\u001b[39m(C_global),m,e,v]= C_troplat*PgperKg\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/u/apps/opt/conda/envs/npl-2025b/lib/python3.12/site-packages/xarray/core/common.py:181\u001b[39m, in \u001b[36mAbstractArray.__array__\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    180\u001b[39m             copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.array(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m, dtype=dtype, copy=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/u/apps/opt/conda/envs/npl-2025b/lib/python3.12/site-packages/xarray/core/dataarray.py:797\u001b[39m, in \u001b[36mDataArray.values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    784\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    785\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> np.ndarray:\n\u001b[32m    786\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    787\u001b[39m \u001b[33;03m    The array's data converted to numpy.ndarray.\u001b[39;00m\n\u001b[32m    788\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    795\u001b[39m \u001b[33;03m    to this array may be reflected in the DataArray as well.\u001b[39;00m\n\u001b[32m    796\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m797\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/u/apps/opt/conda/envs/npl-2025b/lib/python3.12/site-packages/xarray/core/variable.py:536\u001b[39m, in \u001b[36mVariable.values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> np.ndarray:\n\u001b[32m    535\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_as_array_or_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/u/apps/opt/conda/envs/npl-2025b/lib/python3.12/site-packages/xarray/core/variable.py:316\u001b[39m, in \u001b[36m_as_array_or_item\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_as_array_or_item\u001b[39m(data):\n\u001b[32m    303\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the given values as a numpy array, or as an individual item if\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[33;03m    it's a 0d datetime64 or timedelta64 array.\u001b[39;00m\n\u001b[32m    305\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    314\u001b[39m \u001b[33;03m    TODO: remove this (replace with np.asarray) once these issues are fixed\u001b[39;00m\n\u001b[32m    315\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data.ndim == \u001b[32m0\u001b[39m:\n\u001b[32m    318\u001b[39m         kind = data.dtype.kind\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/u/apps/opt/conda/envs/npl-2025b/lib/python3.12/site-packages/dask/array/core.py:1729\u001b[39m, in \u001b[36mArray.__array__\u001b[39m\u001b[34m(self, dtype, copy, **kwargs)\u001b[39m\n\u001b[32m   1722\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   1723\u001b[39m     warnings.warn(\n\u001b[32m   1724\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt acquire a memory view of a Dask array. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1725\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis will raise in the future.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1726\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1729\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1731\u001b[39m \u001b[38;5;66;03m# Apply requested dtype and convert non-numpy backends to numpy.\u001b[39;00m\n\u001b[32m   1732\u001b[39m \u001b[38;5;66;03m# If copy is True, numpy is going to perform its own deep copy\u001b[39;00m\n\u001b[32m   1733\u001b[39m \u001b[38;5;66;03m# after this method returns.\u001b[39;00m\n\u001b[32m   1734\u001b[39m \u001b[38;5;66;03m# If copy is None, finalize() ensures that the returned object\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;66;03m# does not share memory with an object stored in the graph or on a\u001b[39;00m\n\u001b[32m   1736\u001b[39m \u001b[38;5;66;03m# process-local Worker.\u001b[39;00m\n\u001b[32m   1737\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.asarray(x, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/u/apps/opt/conda/envs/npl-2025b/lib/python3.12/site-packages/dask/base.py:373\u001b[39m, in \u001b[36mDaskMethodsMixin.compute\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m    350\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[32m    351\u001b[39m \n\u001b[32m    352\u001b[39m \u001b[33;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    371\u001b[39m \u001b[33;03m    dask.compute\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     (result,) = \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/u/apps/opt/conda/envs/npl-2025b/lib/python3.12/site-packages/dask/base.py:681\u001b[39m, in \u001b[36mcompute\u001b[39m\u001b[34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     expr = expr.optimize()\n\u001b[32m    679\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(flatten(expr.__dask_keys__()))\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     results = \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m repack(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/u/apps/opt/conda/envs/npl-2025b/lib/python3.12/queue.py:171\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be a non-negative number\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/u/apps/opt/conda/envs/npl-2025b/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ## Create a netcdf file with a matrix of processed time series\n",
    "# this works with environment npl2025b\n",
    "# to run on the command line:\n",
    "#\n",
    "# module load conda\n",
    "# conda activate npl-2025b\n",
    "# python create_metrics_matrix.py\n",
    "\n",
    "\n",
    "# This is a script version of a python notebook\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import numpy.ma as ma\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "import time\n",
    "import cftime\n",
    "import netCDF4 as nc\n",
    "from datetime import timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "\n",
    "\n",
    "import nc_time_axis\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\")\n",
    "\n",
    "# --- custom files\n",
    "# load custom functions for analyzing flat10\n",
    "\n",
    "from loading_function_flat10 import load_flat10, load_one_model, load_one_model_onevar, load_grid, select_time_slice, weighted_temporal_mean \n",
    "\n",
    "\n",
    "# ###-------------####\n",
    "# define which runs and models\n",
    "\n",
    "outputdir= '/glade/campaign/cgd/tss/people/aswann/flat10/'\n",
    "\n",
    "modellist_orig= ['ACCESS-ESM1-5',  \n",
    "            'CESM2',    \n",
    "            'GFDL-ESM4',  \n",
    "            'GISS_E2.1',  \n",
    "            'NorESM2-LM',\n",
    "            'MPI-ESM1-2-LR',\n",
    "            'CNRM-ESM2-1',\n",
    "            'HadCM3LC-Bris',\n",
    "            'UKESM1.2']\n",
    "modellist=modellist_orig\n",
    "\n",
    "runlist = ['flat10','flat10_zec','flat10_cdr']\n",
    "# use a wildcard to capture different ways the folders and runs are named across models\n",
    "runlist_wc = ['*lat10','*zec','*cdr']\n",
    "\n",
    "varlist_load=['cVeg','cSoil','cLitter','nbp','gpp','rh','tas','pr'] #, 'gpp','fgco2', 'ra', 'rh']#, 'npp'] # not working beyond nbp for norESM\n",
    "varlist_analyze=['cVeg','cSoil','cTot','cLitter','nbp','gpp','rh','tas','pr']\n",
    "varlist=varlist_load\n",
    "unitslist=['kgC m-2','kgC m-2','kgC m-2','kgC m-2 s-1','kgC m-2 s-1','kgC m-2 s-1','K','kg m-2 s-1']\n",
    "\n",
    "\n",
    "# global and three latitude bands: trop, mid, high\n",
    "latlist=['global','highlat','troplat','midlat']\n",
    "troplat=30\n",
    "highlat=60\n",
    "\n",
    "## unit conversions\n",
    "#unitconversions\n",
    "sperday=60*60*24\n",
    "speryr=60*60*24*365\n",
    "\n",
    "PgperKg = 1e-12\n",
    "# to convert kg m-2 s-1 to kg/m2/yr multiply by speryr\n",
    "\n",
    "# initialize a dictionary to hold all of the data\n",
    "data_dict={}\n",
    "\n",
    "\n",
    "# ###---------------####\n",
    "\n",
    "#-- load grid info\n",
    "data_dict = load_grid(data_dict,modellist)\n",
    "\n",
    "\n",
    "#-- load data\n",
    "#data_dict=load_flat10(data_dict, modellist, runlist, runlist_wc, varlist)\n",
    "\n",
    "#-- toggle to analysis lists\n",
    "modellist=modellist_orig\n",
    "varlist=varlist_load\n",
    "\n",
    "\n",
    "# ###---------------####\n",
    "# create matrix of zonal mean time series for \n",
    "\n",
    "#- initialize\n",
    "C_global_mat= np.empty([350,len(modellist),len(runlist),len(varlist)])\n",
    "C_highlat_mat= np.empty([350,len(modellist),len(runlist),len(varlist)])\n",
    "C_troplat_mat= np.empty([350,len(modellist),len(runlist),len(varlist)])\n",
    "C_midlat_mat= np.empty([350,len(modellist),len(runlist),len(varlist)])\n",
    "\n",
    "# create a time series of years for the first dimension\n",
    "ts= np.arange(350)\n",
    "\n",
    "for m in range(len(modellist)):\n",
    "#for m in range(len(['GFDL-ESM4',  'GISS_E2.1',  'NorESM2-LM','MPI-ESM1-2-LR'])):\n",
    "    model=modellist[m]\n",
    "    print('processing model: ' +model)\n",
    "\n",
    "    # get area and landfrac from the dictionary where they have been pre-loaded\n",
    "    ds_area = data_dict[modellist[m] +'_' +'areacella']\n",
    "    ds_landfrac = data_dict[modellist[m] +'_' +'landfrac']\n",
    "    \n",
    "    #----loop over experiments----# \n",
    "    for e in range(len(runlist)):\n",
    "        run = runlist[e]\n",
    "        print('processing run: ' +run)\n",
    "\n",
    "        #ds=load_one_model(model,runlist_wc[e],varlist)\n",
    "        #ds=data_dict[modellist[m] +'_' +runlist[e]]\n",
    "\n",
    "\n",
    "        #----loop over variables----#\n",
    "        for v in range(len(varlist)):\n",
    "            var=varlist[v]\n",
    "            print('processing variable: ' +var)\n",
    "\n",
    "            ds=load_one_model_onevar(model,runlist_wc[e],var)\n",
    "\n",
    "\n",
    "            if model=='CESM2':\n",
    "                area = ds_area['areacella'].squeeze().reindex_like(ds, method='nearest',tolerance=0.05)\n",
    "            else:\n",
    "                area = ds_area['areacella'].reindex_like(ds, method='nearest',tolerance=0.05)\n",
    "            \n",
    "            landfrac=ds_landfrac['sftlf'].reindex_like(ds, method='nearest',tolerance=0.05)\n",
    "            \n",
    "            if landfrac.max(dim=['lat','lon'])>1: #test if landfrac is on a 0-100 or 0-1 scale\n",
    "                landfrac=landfrac/100\n",
    "                \n",
    "            landarea=area*landfrac\n",
    "             \n",
    "\n",
    "            # NorESM has drift that needs to be corrected\n",
    "            # load the drift correction matrix and remove the drift\n",
    "            if model=='NorESM2-LM':\n",
    "                if var=='cVeg':\n",
    "                    field = pickle.load(open('/glade/campaign/cgd/tss/people/aswann/flat10/NorESM2-LM/NorESM2-LM_2D_TOTVEGC_ann_drift.pkl','rb'))\n",
    "                    adj_matrix = xr.DataArray(np.squeeze(field), dims=['lat','lon'], coords={'latitude': ds.lat, 'longitude':ds.lon})##,unit={'g C m-2 yr-1'})\n",
    "                    ty=ds['time'].dt.year\n",
    "                    tyindx=ty-ty[0]+1\n",
    "                    adjustment = adj_matrix* tyindx*(1/1000) #this is the drift for each time point and each gridcell in kg C m-2 yr-1\n",
    "\n",
    "                    ds[var]=ds[var]+adjustment # remove the drift from the variable\n",
    "                    \n",
    "                elif var=='cSoil':\n",
    "                    field = pickle.load(open('/glade/campaign/cgd/tss/people/aswann/flat10/NorESM2-LM/NorESM2-LM_2D_TOTSOMC_ann_drift.pkl','rb'))\n",
    "                    adj_matrix = xr.DataArray(np.squeeze(field), dims=['lat','lon'], coords={'latitude': ds.lat, 'longitude':ds.lon})##,unit={'g C m-2 yr-1'})\n",
    "                    ty=ds['time'].dt.year\n",
    "                    tyindx=ty-ty[0]+1\n",
    "                    adjustment = adj_matrix* tyindx*(1/1000) #this is the drift for each time point and each gridcell in kg C m-2 yr-1\n",
    "\n",
    "                    ds[var]=ds[var]+adjustment # remove the drift from the variable\n",
    "                    \n",
    "                elif var=='cLitter':\n",
    "                    field = pickle.load(open('/glade/campaign/cgd/tss/people/aswann/flat10/NorESM2-LM/NorESM2-LM_2D_TOTLITC_ann_drift.pkl','rb'))\n",
    "                    adj_matrix = xr.DataArray(np.squeeze(field), dims=['lat','lon'], coords={'latitude': ds.lat, 'longitude':ds.lon})##,unit={'g C m-2 yr-1'})\n",
    "                    ty=ds['time'].dt.year\n",
    "                    tyindx=ty-ty[0]+1\n",
    "                    adjustment = adj_matrix* tyindx*(1/1000) #this is the drift for each time point and each gridcell in kg C m-2 yr-1\n",
    "\n",
    "                    ds[var]=ds[var]+adjustment # remove the drift from the variable\n",
    "\n",
    "            data_var= weighted_temporal_mean(ds, var)\n",
    "\n",
    "            # mask for nans \n",
    "            # Mask landarea where it's zero or NaN to avoid invalid values\n",
    "            valid_mask = (landarea > 0) & landarea.notnull()\n",
    "            masked_landarea = landarea.where(valid_mask)\n",
    "            masked_data = data_var.where(valid_mask)\n",
    "\n",
    "            landarea_global = masked_landarea.sum(dim=['lat','lon'])\n",
    "            landarea_highlat = ((masked_landarea.where(ds.lat>=highlat)).sum(dim=['lat','lon']))\n",
    "            landarea_troplat = ((masked_landarea.where((ds.lat>=-troplat) & (ds.lat<=troplat))).sum(dim=['lat','lon']))\n",
    "            landarea_midlat = ((masked_landarea.where((ds.lat>=troplat) & (ds.lat<=highlat))).sum(dim=['lat','lon']))\n",
    "\n",
    "            if var=='tas' or var=='pr': \n",
    "                C_global =(((masked_data*masked_landarea)).sum(dim=['lat','lon']))/landarea_global\n",
    "                C_highlat=(((masked_data*masked_landarea).where(ds.lat>=highlat)).sum(dim=['lat','lon']))/landarea_highlat\n",
    "                C_troplat=(((masked_data*masked_landarea).where((ds.lat>=-troplat) & (ds.lat<=troplat))).sum(dim=['lat','lon']))/landarea_troplat\n",
    "                C_midlat=(((masked_data*masked_landarea).where((ds.lat>=troplat) & (ds.lat<=highlat))).sum(dim=['lat','lon']))/landarea_midlat\n",
    "    \n",
    "                #put into matrix \n",
    "                C_global_mat[0:len(C_global),m,e,v]= C_global\n",
    "                C_highlat_mat[0:len(C_global),m,e,v]= C_highlat\n",
    "                C_troplat_mat[0:len(C_global),m,e,v]= C_troplat\n",
    "                C_midlat_mat[0:len(C_global),m,e,v]= C_midlat\n",
    "            \n",
    "            else: # it is a carbon variable and we want to make a sum\n",
    "                # total carbon on land. Becuase it is in units of carbon/area (kgC/m2), multiply by area\n",
    "                # our area variable is in m2\n",
    "                C_global =(((masked_data*masked_landarea)).sum(dim=['lat','lon']))\n",
    "                C_highlat=((masked_data*masked_landarea).where(ds.lat>=highlat)).sum(dim=['lat','lon'])\n",
    "                C_troplat=((masked_data*masked_landarea).where((ds.lat>=-troplat) & (ds.lat<=troplat))).sum(dim=['lat','lon'])\n",
    "                C_midlat=((masked_data*masked_landarea).where((ds.lat>=troplat) & (ds.lat<=highlat))).sum(dim=['lat','lon'])\n",
    "    \n",
    "                #put into matrix and convert to PgC (kgC => PgC, divide by 10^12)\n",
    "                C_global_mat[0:len(C_global),m,e,v]= C_global*PgperKg\n",
    "                C_highlat_mat[0:len(C_global),m,e,v]= C_highlat*PgperKg\n",
    "                C_troplat_mat[0:len(C_global),m,e,v]= C_troplat*PgperKg\n",
    "                C_midlat_mat[0:len(C_global),m,e,v]= C_midlat*PgperKg\n",
    "\n",
    "            # reset values after the end of the time series to nan\n",
    "            C_global_mat[(len(C_global)):,m,e,v]=np.nan\n",
    "            C_highlat_mat[(len(C_highlat)):,m,e,v]=np.nan\n",
    "            C_troplat_mat[(len(C_troplat)):,m,e,v]=np.nan\n",
    "            C_midlat_mat[(len(C_midlat)):,m,e,v]=np.nan\n",
    "\n",
    "        del ds # remove the dataset from memory\n",
    "        del data_var # remove from memory\n",
    "        del masked_data\n",
    "\n",
    "# ###----------------####\n",
    "\n",
    "# put the matrix into an xarray dataset\n",
    "data_array_combined = np.full((len(ts), len(modellist), len(runlist), len(varlist), len(latlist)),np.nan)\n",
    "\n",
    "data_array_combined[:,:,:,:,0]=C_global_mat\n",
    "data_array_combined[:,:,:,:,1]=C_highlat_mat\n",
    "data_array_combined[:,:,:,:,2]=C_troplat_mat\n",
    "data_array_combined[:,:,:,:,3]=C_midlat_mat\n",
    "\n",
    "\n",
    "# ###----------------####\n",
    "# put into an xarray dataset\n",
    "\n",
    "ds_C_global= xr.Dataset(\n",
    "    {\n",
    "        \"data\": ([\"time\", \"model\", \"run\", \"var\",\"latrange\"], data_array_combined)\n",
    "    },\n",
    "    coords={\n",
    "        \"time\": ts,\n",
    "        \"model\": modellist,\n",
    "        \"run\": runlist,\n",
    "        \"var\": varlist,\n",
    "        \"latrange\": latlist\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# ###----------------####\n",
    "\n",
    "# - save the matrix to a netcdf file\n",
    "ds_C_global.to_netcdf(\"C_metrics_matrix.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc422e-3fa5-42fa-a3fd-1ddafa5f1a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4054af7d-434a-4ef0-acc4-54feaa810445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9670338-4d3a-421d-8abc-39df3d7eb280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2025b",
   "language": "python",
   "name": "npl-2025b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
